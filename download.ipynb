{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd0d0805dd0a63a9aa5b56409bdcec0789bd27e38c20d1aed221282d406ad418a8c",
   "display_name": "Python 3.9.4 64-bit ('hyp3': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "d0805dd0a63a9aa5b56409bdcec0789bd27e38c20d1aed221282d406ad418a8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Import libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import zipfile\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import hyp3_sdk as sdk\n",
    "from hyp3_sdk import asf_search\n",
    "from hyp3lib import cutGeotiffs\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "source": [
    "Enter Hyp3 credentials"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp3 = sdk.HyP3(prompt=True)\n",
    "my_info = hyp3.my_info()\n",
    "print(f\"Remaining Quota: {my_info['quota']['remaining']}\")"
   ]
  },
  {
   "source": [
    "Create download list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project name\n",
    "# project_name = 'ifg_a_p81_f1048_20x4'\n",
    "project_name = 'tongariro_asc2'\n",
    "\n",
    "# Set date bounds\n",
    "start_date = datetime.datetime(2017, 12, 31)\n",
    "end_date = datetime.datetime(2021, 12, 31)\n",
    "\n",
    "# Read in \n",
    "df = pd.read_csv('..\\\\slcs_asc_path81_frame1048.csv',usecols=['Granule Name', 'Acquisition Date'])\n",
    "\n",
    "# Convert and limit by date\n",
    "df['Acquisition Date'] = pd.to_datetime(df['Acquisition Date'], format='%Y-%m-%dT%H:%M:%S')\n",
    "df = df.loc[(df['Acquisition Date']>=start_date) & (df['Acquisition Date']<=end_date)]\n",
    "df = df.sort_values('Acquisition Date')\n",
    "\n",
    "granules = list(df['Granule Name'])\n",
    "print(f'Will create interferograms for {len(granules)} SLCs')"
   ]
  },
  {
   "source": [
    "Request Ifg generation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insar_jobs = sdk.Batch()\n",
    "first = True\n",
    "for reference in tqdm(granules):\n",
    "    neighbors_metadata = asf_search.get_nearest_neighbors(reference, max_neighbors=3)\n",
    "    for secondary_metadata in neighbors_metadata:\n",
    "        secondary = secondary_metadata['granuleName']\n",
    "        if first:\n",
    "            insar_jobs += hyp3.submit_insar_job(reference, secondary, name=project_name, include_inc_map=True, include_dem=True)\n",
    "            first = False\n",
    "        else:\n",
    "            insar_jobs += hyp3.submit_insar_job(reference, secondary, name=project_name)\n"
   ]
  },
  {
   "source": [
    "Check progress and download"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = hyp3.find_jobs(name=project_name)\n",
    "\n",
    "if batch.complete():\n",
    "    #filter to only succeeded jobs\n",
    "    succeeded_jobs = batch.filter_jobs(succeeded=True, running=False, failed=False)\n",
    "\n",
    "    #download files if not downloaded already\n",
    "    for job in succeeded_jobs.jobs:\n",
    "        filename = job.to_dict()['files'][0]['filename']\n",
    "        location = os.path.join(project_name,filename)\n",
    "        if not os.path.exists(location):\n",
    "            job.download_files(location=project_name,create=True)\n",
    "        \n",
    "    # #download files if not downloaded already\n",
    "    # file_list = succeeded_jobs.download_files(location=project_name,create=True)\n",
    "else:\n",
    "    #to get updated information\n",
    "    batch = hyp3.refresh(batch)\n",
    "    #or to wait until completion and get updated information (which will take a fair bit)\n",
    "    batch = hyp3.watch(batch)"
   ]
  },
  {
   "source": [
    "Unzip files and clip to same extent"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'tongariro_asc'\n",
    "zip_files = glob.glob(os.path.join(project_name,'*.zip'))\n",
    "folders = [x.split('.')[0] for x in zip_files if 'SLC' not in x]\n",
    "\n",
    "for zip_file, folder in tqdm(zip(zip_files, folders)):\n",
    "    if not os.path.isdir(folder):\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(project_name)\n",
    "\n",
    "all_images = []\n",
    "for suffix in ['dem','inc_map','water_map','unw_phase','corr']:\n",
    "    all_images += [os.path.join(x,f'{os.path.basename(x)}_{suffix}.tif') for x in folders]\n",
    "\n",
    "exists = [x for x in all_images if os.path.exists(x)]\n",
    "to_clip = [x for x in exists if not os.path.exists(f'{x[:-4]}_clip.tif')]\n",
    "\n",
    "cutGeotiffs.cutFiles(to_clip)\n"
   ]
  },
  {
   "source": [
    "Done!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}